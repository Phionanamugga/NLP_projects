{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bd4ebdb6",
   "metadata": {},
   "source": [
    "# End-to-End NLP Pipeline for Customer Sentiment Analysis of Amazon Food\n",
    "\n",
    "## Problem Statement\n",
    "\n",
    "Business Problem: Amazon seeks to enhance customer satisfaction by analyzing sentiment in the food sold on its website. Understanding whether reviews are  negative,positive, or neutral can guide marketing strategies,product improvements,  and customer service satisfaction.\n",
    "\n",
    "Importance: Positive sentiment drives customer loyalty, while negative sentiment can harm brand reputation. An automated sentiment analysis system enables reducing manual review efforts ,real-time insights,  and enabling data-driven decisions.\n",
    "\n",
    "Data Collection: We use the Food Reviews Dataset for Amazon, a publicly available dataset on Kaggle having 500,000 reviews by customer with star ratings (1-5). I have mapped out ratings to sentiments: 1-2 (Negative), 3 (Neutral), 4-5 (Positive). This dataset is ideal due to its  diversity, size,and relevance to retail.\n",
    "\n",
    "NLP Task: The problem has been formulated as a multi-class text classification task, where the inputs are the review texts, and outputs are the sentiments (negative, positive, neutral).\n",
    "\n",
    "Benefits: The pipeline will enable the company to prioritize customer concerns,monitor sentiment trends,  and improve product offerings, ultimately boosting revenue and customer retention.\n",
    "\n",
    "System Design\n",
    "The Natural_Langauage_Processing pipeline contains the following; connected sequentially to process textual data:\n",
    "\n",
    "Data Collection: Load and sample the Amazon Food Reviews dataset to ensure manageability.\n",
    "Preprocessing: Text has been cleaned by (removing stopwords, punctuation, lemmatize).\n",
    "\n",
    "Feature Extraction: TF-IDF has been used for baseline models and BERT embeddings for better accuracy.\n",
    "\n",
    "Model Training: A logistic regression model  has been tarined as the baseline and a fine tuning has been done using BERT model for better accuracy.\n",
    "Evaluation: Assessment of precision,accuracy,  recall, F1-score, and confusion matrix has been done.\n",
    "Discussion: Analyze results, limitations, and business implications.\n",
    "\n",
    "\n",
    "\n",
    "1. Data Acquisition\n",
    "\n",
    "We load a subset of the Amazon Reviews dataset (100,000 reviews) to balance computational efficiency and representativeness. The dataset is sourced from Amazonâ€™s public repository."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3139b7c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing libraries for the data collection\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from transformers import BertTokenizer, BertModel\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from transformers import TFBertForSequenceClassification\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "334748b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading the Dataset\n",
    "df_nlp = pd.read_csv(\"/Users/phionanamugga/Documents/coding/datascience/NLP_projects/AmazonFoodReviews.csv\", on_bad_lines='skip')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13096c8f",
   "metadata": {},
   "source": [
    "2. Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b2bf7918",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 568454 entries, 0 to 568453\n",
      "Data columns (total 10 columns):\n",
      " #   Column                  Non-Null Count   Dtype \n",
      "---  ------                  --------------   ----- \n",
      " 0   Id                      568454 non-null  int64 \n",
      " 1   ProductId               568454 non-null  object\n",
      " 2   UserId                  568454 non-null  object\n",
      " 3   ProfileName             568428 non-null  object\n",
      " 4   HelpfulnessNumerator    568454 non-null  int64 \n",
      " 5   HelpfulnessDenominator  568454 non-null  int64 \n",
      " 6   Score                   568454 non-null  int64 \n",
      " 7   Time                    568454 non-null  int64 \n",
      " 8   Summary                 568427 non-null  object\n",
      " 9   Text                    568454 non-null  object\n",
      "dtypes: int64(5), object(5)\n",
      "memory usage: 43.4+ MB\n"
     ]
    }
   ],
   "source": [
    "# Getting summary information i.e data type, null columns and column names\n",
    "df_nlp.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5d1631c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>HelpfulnessNumerator</th>\n",
       "      <th>HelpfulnessDenominator</th>\n",
       "      <th>Score</th>\n",
       "      <th>Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>568454.000000</td>\n",
       "      <td>568454.000000</td>\n",
       "      <td>568454.00000</td>\n",
       "      <td>568454.000000</td>\n",
       "      <td>5.684540e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>284227.500000</td>\n",
       "      <td>1.743817</td>\n",
       "      <td>2.22881</td>\n",
       "      <td>4.183199</td>\n",
       "      <td>1.296257e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>164098.679298</td>\n",
       "      <td>7.636513</td>\n",
       "      <td>8.28974</td>\n",
       "      <td>1.310436</td>\n",
       "      <td>4.804331e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.393408e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>142114.250000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.271290e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>284227.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.311120e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>426340.750000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.00000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.332720e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>568454.000000</td>\n",
       "      <td>866.000000</td>\n",
       "      <td>923.00000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.351210e+09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Id  HelpfulnessNumerator  HelpfulnessDenominator  \\\n",
       "count  568454.000000         568454.000000            568454.00000   \n",
       "mean   284227.500000              1.743817                 2.22881   \n",
       "std    164098.679298              7.636513                 8.28974   \n",
       "min         1.000000              0.000000                 0.00000   \n",
       "25%    142114.250000              0.000000                 0.00000   \n",
       "50%    284227.500000              0.000000                 1.00000   \n",
       "75%    426340.750000              2.000000                 2.00000   \n",
       "max    568454.000000            866.000000               923.00000   \n",
       "\n",
       "               Score          Time  \n",
       "count  568454.000000  5.684540e+05  \n",
       "mean        4.183199  1.296257e+09  \n",
       "std         1.310436  4.804331e+07  \n",
       "min         1.000000  9.393408e+08  \n",
       "25%         4.000000  1.271290e+09  \n",
       "50%         5.000000  1.311120e+09  \n",
       "75%         5.000000  1.332720e+09  \n",
       "max         5.000000  1.351210e+09  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Checking for the Summary description of the Dataset\n",
    "df_nlp.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a58721c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>ProductId</th>\n",
       "      <th>UserId</th>\n",
       "      <th>ProfileName</th>\n",
       "      <th>HelpfulnessNumerator</th>\n",
       "      <th>HelpfulnessDenominator</th>\n",
       "      <th>Score</th>\n",
       "      <th>Time</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>B001E4KFG0</td>\n",
       "      <td>A3SGXH7AUHU8GW</td>\n",
       "      <td>delmartian</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1303862400</td>\n",
       "      <td>Good Quality Dog Food</td>\n",
       "      <td>I have bought several of the Vitality canned d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>B00813GRG4</td>\n",
       "      <td>A1D87F6ZCVE5NK</td>\n",
       "      <td>dll pa</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1346976000</td>\n",
       "      <td>Not as Advertised</td>\n",
       "      <td>Product arrived labeled as Jumbo Salted Peanut...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>B000LQOCH0</td>\n",
       "      <td>ABXLMWJIXXAIN</td>\n",
       "      <td>Natalia Corres \"Natalia Corres\"</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1219017600</td>\n",
       "      <td>\"Delight\" says it all</td>\n",
       "      <td>This is a confection that has been around a fe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>B000UA0QIQ</td>\n",
       "      <td>A395BORC6FGVXV</td>\n",
       "      <td>Karl</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1307923200</td>\n",
       "      <td>Cough Medicine</td>\n",
       "      <td>If you are looking for the secret ingredient i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>B006K2ZZ7K</td>\n",
       "      <td>A1UQRSCLF8GW1T</td>\n",
       "      <td>Michael D. Bigham \"M. Wassir\"</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1350777600</td>\n",
       "      <td>Great taffy</td>\n",
       "      <td>Great taffy at a great price.  There was a wid...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id   ProductId          UserId                      ProfileName  \\\n",
       "0   1  B001E4KFG0  A3SGXH7AUHU8GW                       delmartian   \n",
       "1   2  B00813GRG4  A1D87F6ZCVE5NK                           dll pa   \n",
       "2   3  B000LQOCH0   ABXLMWJIXXAIN  Natalia Corres \"Natalia Corres\"   \n",
       "3   4  B000UA0QIQ  A395BORC6FGVXV                             Karl   \n",
       "4   5  B006K2ZZ7K  A1UQRSCLF8GW1T    Michael D. Bigham \"M. Wassir\"   \n",
       "\n",
       "   HelpfulnessNumerator  HelpfulnessDenominator  Score        Time  \\\n",
       "0                     1                       1      5  1303862400   \n",
       "1                     0                       0      1  1346976000   \n",
       "2                     1                       1      4  1219017600   \n",
       "3                     3                       3      2  1307923200   \n",
       "4                     0                       0      5  1350777600   \n",
       "\n",
       "                 Summary                                               Text  \n",
       "0  Good Quality Dog Food  I have bought several of the Vitality canned d...  \n",
       "1      Not as Advertised  Product arrived labeled as Jumbo Salted Peanut...  \n",
       "2  \"Delight\" says it all  This is a confection that has been around a fe...  \n",
       "3         Cough Medicine  If you are looking for the secret ingredient i...  \n",
       "4            Great taffy  Great taffy at a great price.  There was a wid...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking for the headings in the dataset\n",
    "df_nlp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f9c879b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score\n",
      "5    363122\n",
      "4     80655\n",
      "1     52268\n",
      "3     42640\n",
      "2     29769\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Checking for the value counts of each star rating\n",
    "print(df_nlp['Score'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "39f09585",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mapping Star ratings to Sentiment\n",
    "df_nlp['Sentiment'] = df_nlp['Score'].map({1: 'negative', 2: 'negative', 3: 'neutral', 4: 'positive', 5: 'positive'})\n",
    "df_nlp = df_nlp[['Text', 'Sentiment']].dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a8849e6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "column names: Index(['Text', 'Sentiment'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Printing Column names to verify information\n",
    "print(\"column names:\", df_nlp.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae35a6af",
   "metadata": {},
   "source": [
    "3. Preprocessing\n",
    "\n",
    "Text is cleaned by converting to lowercase, removing punctuation, tokenizing, removing stopwords, and lemmatizing. This reduces noise and standardizes input for feature extraction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "920fcda5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     /Users/phionanamugga/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/phionanamugga/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/phionanamugga/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Downloading the required NLTK data\n",
    "nltk.download('punkt_tab')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# Initializing the Lemmatizer and Stop words\n",
    "Stop_Words = set(stopwords.words('english'))\n",
    "LemmatiZer = WordNetLemmatizer()\n",
    "\n",
    "# Creating a preprocessing function\n",
    "def Preprocess_Text(text):\n",
    "    text = text.lower()\n",
    "    tokens = word_tokenize(text)\n",
    "    tokens = [t for t in tokens if t not in Stop_Words]  # Remove stop words\n",
    "    tokens = [t for t in tokens if t.isalpha()]  # Keeping only alphabetic tokens\n",
    "    tokens = [LemmatiZer.lemmatize(t) for t in tokens]  # Lemmatize tokens\n",
    "    return ' '.join(tokens)\n",
    "\n",
    "# Applying preprocessing to the 'Text' column\n",
    "df_nlp['cleaned_review'] = df_nlp['Text'].apply(Preprocess_Text)\n",
    "print(df_nlp[['Text', 'cleaned_review']].head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
